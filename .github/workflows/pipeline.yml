name: data-observability-pipeline

on:
  workflow_dispatch:
  schedule:
    - cron: "15 */4 * * *"   # every 4 hours at minute 15 (UTC)

jobs:
  run-pipeline:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Check OBS_DATABASE_URL exists
        env:
          OBS_DATABASE_URL: ${{ secrets.OBS_DATABASE_URL }}
        run: |
          if [ -z "${OBS_DATABASE_URL}" ]; then
            echo "OBS_DATABASE_URL is EMPTY"
            exit 1
          else
            echo "OBS_DATABASE_URL is set (length=${#OBS_DATABASE_URL})"
          fi

      # ----------------------------
      # 1️⃣ INGEST
      # ----------------------------
      - name: Run ingestion
        env:
          OBS_DATABASE_URL: ${{ secrets.OBS_DATABASE_URL }}
        run: python -m jobs.ingest

      # ----------------------------
      # 2️⃣ TRANSFORM
      # ----------------------------
      - name: Run transform_fact
        env:
          OBS_DATABASE_URL: ${{ secrets.OBS_DATABASE_URL }}
        run: python -m jobs.transform_fact

      # ----------------------------
      # 3️⃣ DATA QUALITY
      # ----------------------------
      - name: Run data quality checks
        env:
          OBS_DATABASE_URL: ${{ secrets.OBS_DATABASE_URL }}
        run: python -m jobs.run_dq

      # ----------------------------
      # 4️⃣ ANOMALY DETECTION
      # ----------------------------
      - name: Run anomaly detection
        env:
          OBS_DATABASE_URL: ${{ secrets.OBS_DATABASE_URL }}
        run: python -m jobs.run_anomaly_detection
